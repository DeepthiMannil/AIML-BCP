{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\user\\Desktop\\AIML_BC\\Breast-Cancer-Detection-using-Machine-Learning-master\\cancer dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y=LabelEncoder()\n",
    "df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,2:31].values #features that help us determine if patient has cancer or not\n",
    "Y=df.iloc[:,1].values #this is the dataset containing our target variable which indicates diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree Classifier is: 0.9020979020979021\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train,Y_train)\n",
    "cm=confusion_matrix(Y_test,dt.predict(X_test))\n",
    "TP=cm[0][0]\n",
    "TN=cm[1][1]\n",
    "FP=cm[0][1]\n",
    "FN=cm[1][0]\n",
    "print(\"Accuracy of the Decision Tree Classifier is: {}\".format((TP+TN)/(TP+TN+FP+FN)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest Classifier is: 0.958041958041958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train,Y_train)\n",
    "cm2=confusion_matrix(Y_test,rf.predict(X_test))\n",
    "TP=cm2[0][0]\n",
    "TN=cm2[1][1]\n",
    "FP=cm2[0][1]\n",
    "FN=cm2[1][0]\n",
    "print(\"Accuracy of the Random Forest Classifier is: {}\".format((TP+TN)/(TP+TN+FP+FN)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.linear_model import LogisticRegression\\nlog=LogisticRegression (random_state=0)\\nlog.fit(X_train,Y_train)\\ncm3=confusion_matrix(Y_test,log.predict(X_test))\\nTP=cm3[0][0]\\nTN=cm3[1][1]\\nFP=cm3[0][1]\\nFN=cm3[1][0]\\nprint(\"Accuracy of the Logistic Regression Classifier is: {}\".format((TP+TN)/(TP+TN+FP+FN)))'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression (random_state=0)\n",
    "log.fit(X_train,Y_train)\n",
    "cm3=confusion_matrix(Y_test,log.predict(X_test))\n",
    "TP=cm3[0][0]\n",
    "TN=cm3[1][1]\n",
    "FP=cm3[0][1]\n",
    "FN=cm3[1][0]\n",
    "print(\"Accuracy of the Logistic Regression Classifier is: {}\".format((TP+TN)/(TP+TN+FP+FN)))'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#conclusion\n",
    "--------------------\n",
    "Here we can see that the Randomforestclassifier performs better than the DecisionTreeClassifier (Measured using the accuracy of the models: Decision Tree Classifier=0.90, Random Forest Classifier=0.96). DecisionTree classifier builds a single tree and the predictions are based on the rules generated from the Single tree.\n",
    "On the other hand RandomForest is an ensemble model where multiple decision trees are created and the results from all the trees are considered for prediction. Hence Random Forest Tree has a higher performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
